"""
This demo is for constructing a Knowledge Graph from scratch.
Didn't use the Graph Database in this demo
"""
import re
import pandas as pd
import bs4
import requests
import spacy
from spacy import displacy

nlp = spacy.load('en_core_web_sm')

from spacy.matcher import Matcher
from spacy.tokens import span

import networkx as nx
import matplotlib.pyplot as plt
from tqdm import tqdm

pd.set_option('display.max_colwidth', 200)


def get_entities(sentence):
    entity1 = ""
    entity2 = ""

    previous_token_dep = ""  # dependency tag of previous token in the sentence
    previous_token_text = ""  # previous token in the sentence
    prefix = ""
    modifier = ""

    # following code is generated by Copilot automatically. I checked it and did some modifications
    for token in nlp(sentence):
        # check if the token is a punctuation mark. If so, move to next token directly
        if token.dep_ != "punct":
            # check if the token is a compound word or not
            if token.dep_ == "compound":
                prefix = token.text
                # if the previous word was also a 'compound' then add the current word to it
                if previous_token_dep == "compound":
                    prefix = previous_token_text + " " + token.text

            # check if the token is a modifier or not
            if token.dep_.endswith("mod") == True:
                modifier = token.text
                # if the previous word was also a 'compound' then add the current word to it
                if previous_token_dep == "compound":
                    modifier = previous_token_text + " " + token.text

            if token.dep_.find("subj") == True:
                entity1 = modifier + " " + prefix + " " + token.text
                prefix = ""
                modifier = ""
                previous_token_dep = ""
                previous_token_text = ""

            if token.dep_.find("obj") == True:
                entity2 = modifier + " " + prefix + " " + token.text

            # update variables
            previous_token_dep = token.dep_
            previous_token_text = token.text

    return [entity1.strip(), entity2.strip()]


def get_relation(sentence):
    doc = nlp(sentence)

    # Matcher object, which is used to match the pattern and rules
    matcher = Matcher(nlp.vocab)

    pattern = [
        {'DEP': 'ROOT'},
        {'DEP': 'prep', 'OP': '?'},
        {'DEP': 'agent', 'OP': '?'},
        {'POS': 'ADJ', 'OP': '?'}
    ]
    matcher.add("matching_1", [pattern])

    matches = matcher(doc)

    span = doc[matches[-1][1]: matches[-1][2]]

    return span.text


if __name__ == '__main__':
    # import dataset
    candidate_sentences = pd.read_csv("data/wiki_sentences_v2.csv")

    entity_pairs = []

    for sentence in tqdm(candidate_sentences["sentence"]):
        entity_pairs.append(get_entities(sentence))

    relations = [get_relation(sentence) for sentence in tqdm(candidate_sentences['sentence'])]

    # pd.Series(relations).value_counts()[:50]
    # extracted subject
    source = [i[0] for i in entity_pairs]
    # extracted object
    target = [i[1] for i in entity_pairs]

    kg_data = pd.DataFrame({'source': source, 'target': target, 'edge': relations})

    # create a directed-graph from a dataframe
    # G = nx.from_pandas_edgelist(kg_data, "source", "target", True, nx.MultiDiGraph())
    #
    # plt.figure(figsize=(12, 12))

    # pos = nx.spring_layout(G)
    # nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)
    # plt.show()

    # only extract 'composed by' relations
    G = nx.from_pandas_edgelist(kg_data[kg_data['edge'] == "composed by"], "source", "target",
                                edge_attr=True, create_using=nx.MultiDiGraph())

    plt.figure(figsize=(12, 12))
    pos = nx.spring_layout(G, k=0.5)  # k regulates the distance between nodes
    nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap=plt.cm.Blues, pos=pos)
    plt.show()
